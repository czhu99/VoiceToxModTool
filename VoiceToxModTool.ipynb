{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VoiceToxModTool",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbPjousVbpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cea9a35-5c94-4a47-8cfa-6bec0e5958b4"
      },
      "source": [
        "import requests, argparse, os, csv, json\n",
        "from googleapiclient import discovery\n",
        "from googleapiclient.errors import HttpError\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "!pip install discord\n",
        "import discord\n",
        "from dotenv import load_dotenv\n",
        "!pip install nest_asyncio \n",
        "import nest_asyncio \n",
        "from google.colab import drive\n",
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr \n",
        "import os \n",
        "import shutil\n",
        "import csv\n",
        "import glob\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.19.2\n",
            "Collecting discord\n",
            "  Downloading discord-1.7.3-py3-none-any.whl (1.1 kB)\n",
            "Collecting discord.py>=1.7.3\n",
            "  Downloading discord.py-1.7.3-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting aiohttp<3.8.0,>=3.6.0\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.7.3->discord) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.7.3->discord) (3.10.0.2)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<3.8.0,>=3.6.0->discord.py>=1.7.3->discord) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.8.0,>=3.6.0->discord.py>=1.7.3->discord) (2.10)\n",
            "Installing collected packages: multidict, yarl, async-timeout, aiohttp, discord.py, discord\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 discord-1.7.3 discord.py-1.7.3 multidict-5.2.0 yarl-1.7.2\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 100 kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4bVgfnUYCyk",
        "outputId": "3afe5caa-5367-41b0-ae81-ce5c244085f6"
      },
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZbCWf1BgMLx",
        "outputId": "976dec42-c3cf-41ab-b526-c6d42daeb185"
      },
      "source": [
        "%cd /content/drive/My Drive/discord_toxicity_files\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/17PWS8NOX594aI8TH_a9ZdGcCIZPZywzR/discord_toxicity_files\n",
            "speech-to-text\t       train-balanced-sarcasm.csv\n",
            "texts.csv\t       train-balanced-sarcasm-perspective.csv\n",
            "texts_perspective.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L45Qo6EYUvZv"
      },
      "source": [
        "# speech to text\n",
        "r = sr.Recognizer()\n",
        "def get_large_audio_transcription(path):\n",
        "    \"\"\"\n",
        "    Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\n",
        "    \"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_wav(path)  \n",
        "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 500,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence=500)\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk \n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "            # try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened)\n",
        "            except sr.UnknownValueError as e:\n",
        "                pass\n",
        "                \n",
        "            else:\n",
        "                text = f\"{text.capitalize()}. \"\n",
        "                \n",
        "                whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text\n",
        "#Getting all the audio files\n",
        "files = glob.glob('speech-to-text/Audio_trial/wav_format/*.wav')\n",
        "#Getting the channel name\n",
        "info = open('speech-to-text/Audio_trial/info.txt','r')\n",
        "lines = info.readlines()\n",
        "s, l = lines[1].find('\\t')+1, lines[1].find('#')\n",
        "channel = lines[1][s:l]\n",
        "\n",
        "#Conversion to text and saving to csv\n",
        "\n",
        "with open('texts.csv', 'w', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "    writer.writerow([\"Username\", \"Channel\", \"Text\"])\n",
        "    \n",
        "with open('texts.csv', 'a',newline='') as outfile:   \n",
        "    writer = csv.writer(outfile)\n",
        "    for file in files:\n",
        "        username = (re.search('_(.*)_', file[40:])).group(1)\n",
        "        text = get_large_audio_transcription(file)\n",
        "        writer.writerow([username, channel, text])\n",
        "        shutil.rmtree(\"audio-chunks\")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8kjsxVfVTBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acd46b0-b393-40a0-d1fa-7d072879ce12"
      },
      "source": [
        "# perspective api \n",
        "# CONSTANTS\n",
        "API_KEY = 'AIzaSyC0yiBfmliJS4Dmcw0Z8Ao17wRfU2xZSfY'\n",
        "\n",
        "LIMIT_BATCH = 998\n",
        "\n",
        "# GLOBAL DATA STRUCTURE\n",
        "api_responses = []\n",
        "\n",
        "# Callback function for batched requests\n",
        "# Used for collecting the results\n",
        "def gather_results(request_id, response, exception):\n",
        "    global scores\n",
        "    api_responses.append((request_id, response))\n",
        "    \n",
        "    \n",
        "# Read data\n",
        "file = 'texts.csv' #TODO: change name of file to whatever Raima's csv file is called \n",
        "df = pd.read_csv(file)\n",
        "total_rows = len(df)\n",
        "print(\"Total rows = %d\" % (total_rows))\n",
        "\n",
        "# Attributes to request from perspective API\n",
        "attributes = [\"TOXICITY\", \"SEVERE_TOXICITY\", \"IDENTITY_ATTACK\", \"INSULT\",\n",
        "              \"PROFANITY\", \"THREAT\", \"SEXUALLY_EXPLICIT\"]\n",
        "\n",
        "service = discovery.build(\"commentanalyzer\",  \"v1alpha1\",  developerKey=API_KEY, discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\")\n",
        "\n",
        "batch = service.new_batch_http_request(callback=gather_results)\n",
        "\n",
        "count = 0\n",
        "iteration = 0\n",
        "comments = dict()\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    text = row['Text']  # TODO: change to column name of text \n",
        "    analyze_request = {\n",
        "      'comment': { 'text': text },\n",
        "      'requestedAttributes': {attribute:{} for attribute in attributes}\n",
        "    }\n",
        "    batch.add(service.comments().analyze(body=analyze_request), request_id=str(index))\n",
        "    comments[count] = text\n",
        "    count += 1\n",
        "    if (count >= LIMIT_BATCH):\n",
        "        # Send requests in a bulk\n",
        "        batch.execute()\n",
        "        batch = service.new_batch_http_request(callback=gather_results)\n",
        "        iteration += 1\n",
        "        if (iteration % 10 == 0):\n",
        "            num_processed = iteration * LIMIT_BATCH\n",
        "            percentage_finished = num_processed / float(total_rows) * 100\n",
        "            print(\"Processed %d / %d (%.2f percent)\" % (num_processed, total_rows, percentage_finished) )\n",
        "        count = 0\n",
        "\n",
        "batch.execute()\n",
        "print(\"Finish processing the data, write it down to file..\")\n",
        "\n",
        "# Flush data to dataframe\n",
        "for response in api_responses:\n",
        "    index = int(response[0])\n",
        "    json_response = response[1]\n",
        "    if (json_response != None):\n",
        "        for attr in attributes:\n",
        "            column_name = attr.lower() + \"_probability\"\n",
        "            df.loc[index, column_name] = json_response['attributeScores'][attr]['summaryScore']['value']\n",
        "\n",
        "file = 'texts_perspective.csv' ## TODO: change name of file to whatever Chris's file is \n",
        "df.to_csv(file, quoting=csv.QUOTE_NONNUMERIC)\n",
        "print(\"Finish writing the data!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows = 3\n",
            "Finish processing the data, write it down to file..\n",
            "Finish writing the data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgcXkeH8WoKU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "cce73f89-5b9a-4377-84e6-fb06ab6b21be"
      },
      "source": [
        "# discord bot sends alerts \n",
        "nest_asyncio.apply()\n",
        "\n",
        "THRESHOLD = 0.8\n",
        "\n",
        "df = pd.read_csv('texts_perspective.csv')\n",
        "sorted_df = df.sort_values(by=['toxicity_probability'], ascending=False)\n",
        "\n",
        "\n",
        "#load_dotenv()\n",
        "TOKEN = 'OTAyMzg1ODM2MTY1ODM2ODYx.YXdqTA.rqrOg_SxDd2Jr1lx9lgPKW1Rxf4'\n",
        "GUILD = 'MockDiscord'\n",
        "\n",
        "client = discord.Client()\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    #moderator-only channel\n",
        "    channel = client.get_channel(896922980800671767)\n",
        "    \n",
        "    for ind in sorted_df.index:\n",
        "        score = sorted_df['toxicity_probability'][ind]\n",
        "        if score >= THRESHOLD:\n",
        "            name = sorted_df['Username'][ind]\n",
        "            #discriminator = sorted_df['Discriminator'][ind]\n",
        "            voice_channel = sorted_df['Channel'][ind]\n",
        "            message = f'Alert: User {name}has reached a toxicity probability of {score} in voice channel #{voice_channel}'\n",
        "            await channel.send(message)\n",
        "\n",
        "    \n",
        "\n",
        "client.run(TOKEN)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-6-c5420efbc6c4>\", line 32, in <module>\n",
            "    client.run(TOKEN)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/discord/client.py\", line 719, in run\n",
            "    _cleanup_loop(loop)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/discord/client.py\", line 95, in _cleanup_loop\n",
            "    loop.close()\n",
            "  File \"/usr/lib/python3.7/asyncio/unix_events.py\", line 55, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.7/asyncio/selector_events.py\", line 88, in close\n",
            "    raise RuntimeError(\"Cannot close a running event loop\")\n",
            "RuntimeError: Cannot close a running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    }
  ]
}